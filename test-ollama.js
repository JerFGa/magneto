// Test script para verificar la conexi√≥n con Ollama
const { Ollama } = require('ollama');

async function testOllama() {
  console.log('üîç Verificando conexi√≥n con Ollama...\n');
  
  const ollama = new Ollama({ host: 'http://localhost:11434' });
  
  try {
    console.log('üì° Intentando generar una pregunta de prueba...');
    
    const response = await ollama.chat({
      model: 'llama3.1:8b',
      messages: [{ 
        role: 'user', 
        content: 'Genera una pregunta corta para una entrevista de trabajo en tecnolog√≠a.' 
      }],
      stream: false,
    });

    console.log('\n‚úÖ ¬°Conexi√≥n exitosa con Ollama!\n');
    console.log('üìù Pregunta generada:');
    console.log('------------------');
    console.log(response.message.content);
    console.log('------------------\n');
    console.log('‚ú® La integraci√≥n est√° funcionando correctamente.');
    
  } catch (error) {
    console.error('\n‚ùå Error al conectar con Ollama:\n');
    console.error(error.message);
    console.log('\nüîß Soluciones posibles:');
    console.log('1. Aseg√∫rate de que Ollama est√° corriendo: ollama serve');
    console.log('2. Verifica que llama3.1 est√° instalado: ollama list');
    console.log('3. Si no tienes el modelo: ollama pull llama3.1\n');
  }
}

testOllama();
